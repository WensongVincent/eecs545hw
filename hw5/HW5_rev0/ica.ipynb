{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zNmLmqrJAXXp"
   },
   "source": [
    "# EECS 545 (WN 2023) Homework 5: ICA\n",
    "\n",
    "<span class=\"instruction\">Before starting the assignment, please fill in the following cell.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "###################################################################\n",
    "# Enter your first and last name, e.g. \"John Doe\"                 #\n",
    "# for example                                                     #\n",
    "# __NAME__ = \"Anthony Liu\"                                        #\n",
    "# __UNIQID__ = \"anthliu\"                                          #\n",
    "###################################################################\n",
    "raise NotImplementedError(\"TODO: Add your implementation here.\")\n",
    "###################################################################\n",
    "#                        END OF YOUR CODE                         #\n",
    "###################################################################\n",
    "\n",
    "print(f\"Your name and email: {__NAME__} <{__UNIQID__}@umich.edu>\")\n",
    "assert __NAME__ and __UNIQID__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hbe3wUpVAjma"
   },
   "source": [
    "# ICA\n",
    "\n",
    "In this notebook, you will test your ICA implementation from `ica.py` to perform **audio separation**. You will load a sound file with several mixed sources and produce new sound tracks with unmixed sources predicted from ICA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eYE9thuXn4zP"
   },
   "source": [
    "## Setup code\n",
    "Before getting started, we need to run some boilerplate code to set up our environment. You'll need to rerun this setup code each time you start the notebook. Let's start by checking whether we are using Python 3.10 or higher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QqEfH2Rpn9J3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "if sys.version_info[0] < 3:\n",
    "    raise Exception(\"You must use Python 3\")\n",
    "\n",
    "if sys.version_info[1] < 11:\n",
    "    print(\"Autograder will execute your code based on Python 3.11 environment. Please use Python 3.11 or higher to prevent any issues\")\n",
    "    print(\"You can create a conda environment with Python 3.11 like 'conda create --name eecs545 python=3.11'\")\n",
    "    raise Exception(\"Python 3 version is too low: {}\".format(sys.version))\n",
    "else:\n",
    "    print(\"You are good to go\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, run this cell load the [autoreload](https://ipython.readthedocs.io/en/stable/config/extensions/autoreload.html) extension. This allows us to edit `.py` source files, and re-import them into the notebook for a seamless editing and debugging experience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GaCqHOm9oPB3"
   },
   "source": [
    "Then, we run some setup code for this notebook: Import some useful packages and increase the default figure size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "oCaNVx6JoWid",
    "outputId": "2133e4c6-8a6e-4ea3-dd97-23ad471ba2b0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# install required libraries\n",
    "\n",
    "# need scipy for writing wav files\n",
    "!pip install numpy matplotlib scipy\n",
    "\n",
    "# import libraries\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# set figure size\n",
    "plt.rcParams['figure.figsize'] = (5.0, 4.0)\n",
    "plt.rcParams['font.size'] = 10\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O3EvIZ0uAOVN",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import display_html, HTML\n",
    "\n",
    "display_html(HTML('''\n",
    "<style type=\"text/css\">\n",
    "  .instruction { background-color: yellow; font-weight:bold; padding: 3px; }\n",
    "</style>\n",
    "'''));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ica\n",
    "ica.hello()   # should print \"Hello from ica.py!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "Let's load the sound data. This data contains mixed sound signals from multiple microphones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import Audio, display\n",
    "\n",
    "Fs = 11025  # sampling rate\n",
    "def normalize(dat):\n",
    "    return 0.99 * dat / np.max(np.abs(dat))\n",
    "\n",
    "mix = np.loadtxt('data/ica_data.dat')\n",
    "X = normalize(mix)\n",
    "print(f'Loaded {X.shape[0] / Fs:.2f} seconds of audio with {X.shape[1]} microphones.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can play the sound files directly in our IPython notebook! The following code should produce some widgets that can play each unmixed microphone track."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(X.shape[1]):\n",
    "    print(f'Microphone {i}:')\n",
    "    display(Audio(X[:, i], rate=Fs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning the filter *W*\n",
    "\n",
    "<p class=\"instruction\">Implement the `ica.filter_grad()` function. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function computes the SGD update for ICA. This function will be used with `ica.unmixer` to find a filter `W` that we can use to unmix our sources `X`.\n",
    "\n",
    "The following code should take around up to 1~2 minutes to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "W = ica.unmixer(X)\n",
    "print('W solution:\\n', W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unmixing with *W*\n",
    "<p class=\"instruction\">Implement the `ica.unmix` function. </p> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use our `W` to unmix our original sources `X`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "S = normalize(ica.unmix(X, W))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(X.shape[1]):\n",
    "    print(f'Unmixed source {i}:')\n",
    "    display(Audio(S[:, i], rate=Fs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does it sound? Some overlap in sources may be present, but the sound sources should be pretty clearly separated. If you still hear some significant overlap, something is probably wrong in your implementation..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the unmixed sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy.io.wavfile import write\n",
    "\n",
    "for i in range(X.shape[1]):\n",
    "    print(f'Saving unmixed track {i}.')\n",
    "    write(f'ica_unmixed_track_{i}.wav', Fs, S[:, i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission\n",
    "\n",
    "<p class=\"instruction\">Report the *W* matrix you found in your final report. Submit this file along with ica.py to the autograder.</p> \n",
    "Make sure your unmixed source sound tracks are playable when you submit. These audio files will be embedded in the notebook and we may check these files when grading. You do <b>not</b> need to submit the saved unmixed `wav` tracks!"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "eYE9thuXn4zP",
    "CdowvtJen-IP",
    "KtMy3qeipNK3",
    "Hbe3wUpVAjma",
    "lJqim3P1qZgv",
    "ZLdCF3B-AOVT",
    "7XNJ3ydEAOVW",
    "vExP-7n3AOVa",
    "LjAUalCBAOVd",
    "8cPIajWNAOVg",
    "_CsYAv3uAOVi",
    "ixxgq5RKAOVl",
    "OlVbXxmPNzPY",
    "rDNZ8ZAnN7hj",
    "QpSrK3olUfOZ",
    "3zFWkxebWXtu",
    "mVCEro4FAOVq",
    "UG56gKWsAOVv",
    "37R_J2uMP3d-"
   ],
   "name": "two_layer_net.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
